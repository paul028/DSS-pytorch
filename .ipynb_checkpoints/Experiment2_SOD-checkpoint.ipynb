{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from solver import Solver\n",
    "import glob\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.transforms as standard_transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from own_dataloader import Rescale\n",
    "from own_dataloader import RescaleT\n",
    "from own_dataloader import RandomCrop\n",
    "from own_dataloader import CenterCrop\n",
    "from own_dataloader import ToTensor\n",
    "from own_dataloader import ToTensorLab\n",
    "from own_dataloader import SalObjDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir =   'C:/Users/tip/Documents/GitHub/Saliency_Dataset/dataset_test/DUTOMRON/'\n",
    "#data_dir =   'C:/Users/tip/Documents/GitHub/Saliency_Dataset/dataset_test/DUTS-TE/'\n",
    "#data_dir =   'C:/Users/tip/Documents/GitHub/Saliency_Dataset/dataset_test/ECSSD/'\n",
    "#data_dir =   'C:/Users/tip/Documents/GitHub/Saliency_Dataset/dataset_test/HKU-IS/'\n",
    "data_dir =   'C:/Users/tip/Documents/GitHub/Saliency_Dataset/dataset_test/PASCALS/'\n",
    "#data_dir =   'C:/Users/tip/Documents/GitHub/Saliency_Dataset/dataset_test/SOD/'\n",
    "#tra_image_dir = 'DUTS-TR/DUTS-TR-Image/'\n",
    "#tra_label_dir = 'DUTS-TR/DUTS-TR-Mask/'\n",
    "test_image_dir = 'Imgs/'\n",
    "test_label_dir = 'gt/'\n",
    "enableInpaintAug = False\n",
    "batch_size_train=32\n",
    "batch_size_val=32\n",
    "\n",
    "image_ext = '.jpg'\n",
    "label_ext = '.png'\n",
    "\n",
    "vgg_path = 'D:/nonat project/Experiment 1/weights/vgg16_feat.pth'\n",
    "trained_model='D:/nonat project/Experiment 1/weights/Experiment1.pth'\n",
    "\n",
    "#test_folder='D:/nonat project/Experiment 1/weights/test/DUTOMRON TEST'\n",
    "#test_folder='D:/nonat project/Experiment 1/weights/test/DUTS TEST'\n",
    "#test_folder='D:/nonat project/Experiment 1/weights/test/ECCSD TEST'\n",
    "#test_folder='D:/nonat project/Experiment 1/weights/test/HKU-IS TEST'\n",
    "test_folder='D:/nonat project/Experiment 1/weights/test/PASCAL TEST'\n",
    "#test_folder='D:/nonat project/Experiment 1/weights/test/SOD TEST'\n",
    "\n",
    "#output_path='D:/nonat project/Experiment 1/Experiment 1 Predictions/DUTS OMRON Saliency Map Prediction/'\n",
    "#output_path='D:/nonat project/Experiment 1/Experiment 1 Predictions/DUTS Saliency Map Prediction/'\n",
    "#output_path='D:/nonat project/Experiment 1/Experiment 1 Predictions/ECCSD Saliency Map Prediction/'\n",
    "#output_path='D:/nonat project/Experiment 1/Experiment 1 Predictions/HKU-IS Saliency Map Prediction/'\n",
    "output_path='D:/nonat project/Experiment 1/Experiment 1 Predictions/PASCAL Saliency Map Prediction/'\n",
    "#output_path='D:/nonat project/Experiment 1/Experiment 1 Predictions/SOD Saliency Map Prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "\n",
    "    if config.mode == 'train':\n",
    "        tra_img_name_list = glob.glob(data_dir + tra_image_dir + '*' + image_ext)\n",
    "        print(\"data_dir + tra_image_dir + '*' + image_ext: \", data_dir + tra_image_dir + '*' + image_ext)\n",
    "\n",
    "        tra_lbl_name_list = []\n",
    "        for img_path in tra_img_name_list:\n",
    "        \timg_name = img_path.split(\"\\\\\")[-1]\n",
    "        \taaa = img_name.split(\".\")\n",
    "        \tbbb = aaa[0:-1]\n",
    "        \timidx = bbb[0]\n",
    "        \tfor i in range(1,len(bbb)):\n",
    "        \t\timidx = imidx + \".\" + bbb[i]\n",
    "        \ttra_lbl_name_list.append(data_dir + tra_label_dir + imidx + label_ext)\n",
    "\n",
    "        print(\"---\")\n",
    "        print(\"train images: \", len(tra_img_name_list))\n",
    "        print(\"train labels: \", len(tra_lbl_name_list))\n",
    "        print(\"---\")\n",
    "\n",
    "        train_num = len(tra_img_name_list)\n",
    "        salobj_dataset = SalObjDataset(\n",
    "            img_name_list=tra_img_name_list,\n",
    "            lbl_name_list=tra_lbl_name_list,\n",
    "            transform=transforms.Compose([\n",
    "                RescaleT(256),\n",
    "                RandomCrop(224),\n",
    "                ToTensorLab(flag=0)]),\n",
    "        \t\tcategory=\"train\",\n",
    "        \t\tenableInpaintAug=enableInpaintAug)\n",
    "\n",
    "    test_img_name_list = glob.glob(data_dir + test_image_dir + '*' + image_ext)\n",
    "    print(\"data_dir + test_image_dir + '*' + image_ext: \", data_dir + test_image_dir + '*' + image_ext)\n",
    "    test_lbl_name_list = []\n",
    "    for img_path in test_img_name_list:\n",
    "    \timg_name = img_path.split(\"\\\\\")[-1]\n",
    "    \taaa = img_name.split(\".\")\n",
    "    \tbbb = aaa[0:-1]\n",
    "    \timidx = bbb[0]\n",
    "    \tfor i in range(1,len(bbb)):\n",
    "    \t\timidx = imidx + \".\" + bbb[i]\n",
    "    \ttest_lbl_name_list.append(data_dir + test_label_dir + imidx + label_ext)\n",
    "\n",
    "    print(\"---\")\n",
    "    print(\"test images: \", len(test_img_name_list))\n",
    "    print(\"test labels: \", len(test_lbl_name_list))\n",
    "    print(\"---\")\n",
    "\n",
    "    test_num = len(test_img_name_list)\n",
    "    salobj_dataset_test = SalObjDataset(\n",
    "        img_name_list=test_img_name_list,\n",
    "        lbl_name_list=test_lbl_name_list,\n",
    "        transform=transforms.Compose([\n",
    "            RescaleT(256),\n",
    "            RandomCrop(224),\n",
    "            ToTensorLab(flag=0)]),\n",
    "    \t\tcategory=\"test\",\n",
    "    \t\tenableInpaintAug=enableInpaintAug)\n",
    "    if config.mode == 'train':\n",
    "        train_loader = DataLoader(salobj_dataset, batch_size=config.batch_size, shuffle=True, num_workers=1)\n",
    "        if config.val:\n",
    "        \tval_loader = DataLoader(salobj_dataset_test, batch_size=config.batch_size_val, shuffle=True, num_workers=1)\n",
    "        run = 0\n",
    "        while os.path.exists(\"%s/run-%d\" % (config.save_fold, run)): run += 1\n",
    "        os.mkdir(\"%s/run-%d\" % (config.save_fold, run))\n",
    "        os.mkdir(\"%s/run-%d/logs\" % (config.save_fold, run))\n",
    "        # os.mkdir(\"%s/run-%d/images\" % (config.save_fold, run))\n",
    "        os.mkdir(\"%s/run-%d/models\" % (config.save_fold, run))\n",
    "        config.save_fold = \"%s/run-%d\" % (config.save_fold, run)\n",
    "        if config.val:\n",
    "            train = Solver(train_loader, val_loader, None, config)\n",
    "        else:\n",
    "            train = Solver(train_loader, None, None, config)\n",
    "        train.train(100)\n",
    "    elif config.mode == 'test':\n",
    "        test_loader = DataLoader(salobj_dataset_test, batch_size=batch_size_val, shuffle=True, num_workers=1)\n",
    "        if not os.path.exists(config.test_fold): os.mkdir(config.test_fold)\n",
    "        test = Solver(None, None, test_loader, config)\n",
    "        test.test(100,output_path, use_crf=config.use_crf)\n",
    "    else:\n",
    "        raise IOError(\"illegal input!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir + test_image_dir + '*' + image_ext:  C:/Users/tip/Documents/GitHub/Saliency_Dataset/dataset_test/PASCALS/Imgs/*.jpg\n",
      "---\n",
      "test images:  850\n",
      "test labels:  850\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_root = os.path.join(os.path.expanduser('~'), 'data')\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyper-parameters\n",
    "    parser.add_argument('--n_color', type=int, default=3)\n",
    "    parser.add_argument('--img_size', type=int, default=256)  # 256\n",
    "    parser.add_argument('--lr', type=float, default=1e-6)\n",
    "    parser.add_argument('--clip_gradient', type=float, default=1.0)\n",
    "    parser.add_argument('--cuda', type=bool, default=False)\n",
    "\n",
    "    # Training settings\n",
    "    parser.add_argument('--vgg', type=str, default=vgg_path)\n",
    "    parser.add_argument('--epoch', type=int, default=500)\n",
    "    parser.add_argument('--val', type=bool, default=True)\n",
    "\n",
    "    parser.add_argument('--num_thread', type=int, default=4)\n",
    "    parser.add_argument('--load', type=str, default='')\n",
    "    parser.add_argument('--save_fold', type=str, default='./results')\n",
    "    parser.add_argument('--epoch_val', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=batch_size_train)\n",
    "    parser.add_argument('--batch_size_val', type=int, default=batch_size_val)\n",
    "    parser.add_argument('--epoch_save', type=int, default=10)\n",
    "    parser.add_argument('--epoch_show', type=int, default=1)\n",
    "    parser.add_argument('--pre_trained', type=str, default=None)\n",
    "\n",
    "    # Testing settings\n",
    "    parser.add_argument('--model', type=str, default=trained_model)\n",
    "    parser.add_argument('--test_fold', type=str, default='./results/test')\n",
    "    parser.add_argument('--use_crf', type=bool, default=False)\n",
    "\n",
    "    # Misc\n",
    "    parser.add_argument('--mode', type=str, default='train', choices=['train', 'test'])\n",
    "    parser.add_argument('--visdom', type=bool, default=False)\n",
    "\n",
    "    import easydict\n",
    "    \n",
    "    config =  easydict.EasyDict({\n",
    "    \n",
    "   \"n_color\": 3,\n",
    "    \"img_size\":256,\n",
    "    \"lr\":1e-6,\n",
    "    \"clip_gradient\":1.0,\n",
    "    \"cuda\":True,\n",
    "\n",
    "    \"vgg\":vgg_path,\n",
    "    \"epoch\":500,\n",
    "    \"val\":True,\n",
    "        \n",
    "    \"num_thread\":4,\n",
    "    \"load\":'',\n",
    "    \"save_fold\":'./results',\n",
    "    \"epoch_val\":10,\n",
    "    \"batch_size\":batch_size_train,\n",
    "    \"batch_size_val\":batch_size_val,\n",
    "    \"epoch_save\":10,\n",
    "    \"epoch_show\":1,\n",
    "    \"pre_trained\":None,\n",
    "\n",
    "    \"model\":trained_model,\n",
    "    \"test_fold\":'./results/test',\n",
    "    \"use_crf\":False,\n",
    "\n",
    "    \"mode\":'test',\n",
    "    \"visdom\":False,\n",
    "})\n",
    "    if not os.path.exists(config.save_fold): os.mkdir(config.save_fold)\n",
    "    main(config)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
